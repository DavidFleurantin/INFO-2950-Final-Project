{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 2950 - Project Phase IV\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: David Fleurantin (djf252) and Meredith Hu (mmh264)\n",
    "</br>\n",
    "GitHub: https://github.com/DavidFleurantin/INFO-2950-Final-Project\n",
    "</br>\n",
    "Google Drive Link: https://drive.google.com/drive/folders/1iBHVGOBGvDMe7iT7gU4-bCawfUNaYZwe?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.shopify.com/s/files/1/0072/7315/2579/articles/wallstreet_blog_grande.jpg?v=1598894414\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "Image(url= \"https://cdn.shopify.com/s/files/1/0072/7315/2579/articles/wallstreet_blog_grande.jpg?v=1598894414\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short squeeze of the stock price of GameStop (GME), an American video game retailer, occurred during January 2021. Approximately 140 percent of GameStop's public float had been sold short, and the rush to buy shares to cover those positions as the price rose caused it to rise even farther. Major hedge funds and other large short sellers experienced large and swift financial losses as the price of GME spiraled out of control. The short squeeze was initially catalyzed by members of the the Reddit subreddit [r/wallstreetbets](https://www.reddit.com/r/wallstreetbets/). On January 28th, the short squeeze caused GameStop's stock price to reach a value of oven opening value of US \\\\$500 per share, nearly 30 times the \\\\$17.25 valuation at the beginning of the month. Many people have urged regulators to investigate r/wallstreetbets for stock manipulation while also suggesting that the subreddit be removed on reddit for promoting hate speech. \n",
    "\n",
    "The purpose of our project is to assist regulators and moderators as they evaluate the overall post sentiment of r/wallstreetbets and determine if any action should be taken against the subreddit. To answer this question, we examined a subset of GameStop related reddit posts that were made on the r/wallstreetbets during the height of the subreddit's activity from late January to early April. We trained a multivariate linear model that predicted the sentiment polarity of a r/wallstreetbetsreddit post, either positive or negative, using the following features: the number of upvotes that the post received, the number of comments that the post received, the character count of the post's body text, the period during the day the post was authored - morning/afternoon/evening/night. Ultimately, we found our linear model to not be accurate in predicting r/wallstreetbets post title sentiment. We do not recommend our model to regulators or moderators looking to take sweeping action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. For what purpose was the dataset created? Was there a specific task in mind? Was there a specific gap that needed to be filled?**\n",
    "   - Reddit data - was created to capture the sentiments of r/wallstreetbets in their posts during the meteoric rise of GME stock. WallStreetBets (r/wallstreetbets, also known as WSB), is a subreddit where participants discuss stock and option trading. It has become notorious for its profane nature and allegations of its users manipulating securities. Recently the community became mainstream again with its interest on GameStop shares.\n",
    "    \n",
    "**2. Who created the dataset and on behalf of which entity?**\n",
    "   - Reddit - Data Scientist and Kaggle contributor, [Gabriel Preda](https://www.kaggle.com/gpreda), to satisfy a research need \n",
    "\n",
    "**3. What do the instances that comprise the dataset represent?**\n",
    "   - Reddit - the data contains the 'title', 'score', 'url', 'number of comments', 'time of creation', 'post body', 'timestamp', and associated 'post id'. All of these instances serve to identify exactly 1 r/wallstreetbets post by a user at a particular time.\n",
    "\n",
    "**4. How many instances are there in total?**\n",
    "   - Reddit - There are 42552 total posts captured\n",
    "\n",
    "**5. How was the data associated with each instance acquired? Was the data directly observable, reported by subjects, or indirectly inferred/derived from other data? If data was reported by subjects or indirectly inferred/derived from other data, was the data validated/verified?**\n",
    "   - Reddit - the data was downloaded from https://www.reddit.com/r/wallstreetbets/ using `praw` (The Python Reddit API Wrapper) by the dataset's creator.\n",
    " \n",
    "**6. Does the dataset contain all possible instances or is it a sample of instances from a larger set? If the dataset is a sample, then what is the larger set? Is the sample representative of the larger set?**\n",
    "   - Reddit - the dataset is any actively growing sample of all r/wallstreetbets posts from Jan. 28, 2021 to present. Around Jan. 28, r/wallstreetbets was at its peak in media attention and coincided with the peak of GME stock. The sample may not be representative of the larger set since post topics on Reddit are not static (i.e. what users post today may not mirror the topics that they will post about tomorrow).\n",
    "    \n",
    "**7. Over what timeframe was the data collected? Does this timeframe match the creation timeframe of the data associated with the instances?**\n",
    "   - Reddit - From January 28, 2021 to present (March 19, 2021)\n",
    "   \n",
    "**8. What data does each instance consist of? “Raw” data or features? In either case, please provide a description.**\n",
    "   - Reddit - Raw user post data\n",
    "\n",
    "**9. Is any information missing from individual instances? If so, please provide a description, explaining why this information is missing.**\n",
    "   - Reddit - some values in the 'body' column were NaN. This was done by the creator of the data set to indicate that the post had no post body.\n",
    "\n",
    "**10. Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?**\n",
    "   - Reddit - the data contains a copious amount of harsh language/emojis, which is used in a joking fashion, inside post titles and post bodies. The posts were not filtered in order to preserve the nature of r/wallstreetbets.\n",
    "    \n",
    "**11. Does the dataset relate to people? If not, you may skip the remaining questions in this section.**\n",
    "   - Reddit - the data captures direct postings by Reddit (a public social media platform) users.\n",
    "\n",
    "**12. Is it possible to identify individuals, either directly or indirectly from the dataset?**\n",
    "   - Reddit - it is not possible to identify users by their posts unless they choose to identify themselves in their post (self-doxing). The usernames of each user are not provided in the dataset. However, the url of each post is identified and can be used to find the respective post on Reddit.\n",
    "\n",
    "\n",
    "**14. Were the individuals in question notified about the data collection? Did the individuals in question consent to the collection and use of their data?**\n",
    "   - Reddit - No, the individuals were not notified about the data collection. However, Reddit is a public platform where all posts are publicly visible, so they did consent to the use of their data. As an interesting addendum, though, when r/wallstreetbets received increased media attention and its posts were documented by the media, users of the subreddit were either filled with pride/bravado or anger due to perceived misrepresentation of their posts. At points even CNBC (financial news) read r/wallstreetbets posts during TV broadcasts.\n",
    "\n",
    "**15. Was any preprocessing/cleaning/labeling of the data done?.**\n",
    "   - Reddit - The 'created', 'url', and 'id' columns were useless to our planned analysis, so we removed them. Reddit gives users the option to provide a body to whatever topic that they post. The 'body' text was not much of particular interest to us. However, we felt that it was necessary to capture the length of each post body in case it was useful in analysis. We did this by deciding that a post that was 1000 characters long would have a 'body' value of 1000, while a post with no body (NaN) would have a 'body' value of 0. The timestamp column was converted into a datetime object from a string in order to enable easier comparisons.\n",
    "    \n",
    "**16. Is the software used to preprocess/clean/label the instances available? If so, please provide a link or other access point.**\n",
    "   - Reddit - the dataset creator utilized [praw](https://praw.readthedocs.io/en/latest/) to scrape r/wallstreetbets post\n",
    "\n",
    "**17. Where can your raw source data be found, if applicable? Provide a link to the raw data.**\n",
    "   - The dataset can be found here (Make sure to use a Cornell account to view) -> https://drive.google.com/drive/folders/1afEt08iEISR9dxVcrv-lBQych2ZslX0d?usp=sharing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning and Curation steps have been excluded. Please refer to Data Appendix Folder for for more details. \n",
    "</br>\n",
    "Datasets can be found here: https://drive.google.com/drive/folders/1iBHVGOBGvDMe7iT7gU4-bCawfUNaYZwe?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### r/wallstreetbets Posts and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GME Premarket 🍁 Musk approved 🎮🛑💎✋</td>\n",
       "      <td>562</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:17:28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  comms_num body  \\\n",
       "0  Math Professor Scott Steiner says the numbers ...    110         23  NaN   \n",
       "1  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "2  Not to distract from GME, just thought our AMC...     71        156  NaN   \n",
       "3  Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "4                 GME Premarket 🍁 Musk approved 🎮🛑💎✋    562         97  NaN   \n",
       "\n",
       "            timestamp  body_len  \n",
       "0 2021-01-28 21:32:10       0.0  \n",
       "1 2021-01-28 21:28:57       0.0  \n",
       "2 2021-01-28 21:26:56       0.0  \n",
       "3 2021-01-28 21:19:16       0.0  \n",
       "4 2021-01-28 21:17:28       0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load Reddit (WSB) data\n",
    "reddit_data = pd.read_csv(\"reddit_wsb_gme.csv\")\n",
    "reddit_data = reddit_data.reset_index(drop=True)\n",
    "reddit_data['timestamp'] = pd.to_datetime(reddit_data['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8809.000000</td>\n",
       "      <td>8809.000000</td>\n",
       "      <td>8809.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1819.785787</td>\n",
       "      <td>343.753548</td>\n",
       "      <td>526.592349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9491.172973</td>\n",
       "      <td>3693.024629</td>\n",
       "      <td>1501.850955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>248.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>225870.000000</td>\n",
       "      <td>93268.000000</td>\n",
       "      <td>34984.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score     comms_num      body_len\n",
       "count    8809.000000   8809.000000   8809.000000\n",
       "mean     1819.785787    343.753548    526.592349\n",
       "std      9491.172973   3693.024629   1501.850955\n",
       "min         0.000000      0.000000      0.000000\n",
       "25%         1.000000      2.000000      0.000000\n",
       "50%        37.000000     15.000000      0.000000\n",
       "75%       248.000000     62.000000    323.000000\n",
       "max    225870.000000  93268.000000  34984.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preregistration Statement\n",
    "\n",
    "We aim to provide an answer to the following question through data analysis and evaluation of statistically significant results. \n",
    "\n",
    "#### Using a variety of reddit post features—post upvote score, number of comments, post body length, and time of day published (morning, afternoon, evening, night)— can we accurately predict the sentiment polarity of the post, either positive or negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer this question, we must develop a methodology for scoring each post based upon its sentiment value. After much consideration we discovered a python library named `sentifish`. sentifish is a Python library for Sentiment analysis of textual data(only English).By using sentifish it is very easy to perform tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification etc. For more information please refer to the following reference page [here](https://pypi.org/project/sentifish/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download `sentifish` and import the `Sentiment` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentifish in c:\\users\\djfle\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: cryptography in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from sentifish) (3.1.1)\n",
      "Requirement already satisfied: pandass in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from sentifish) (1.11.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from sentifish) (1.1.3)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from cryptography->sentifish) (1.14.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from cryptography->sentifish) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from pandas->sentifish) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from pandas->sentifish) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from pandas->sentifish) (1.19.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\djfle\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography->sentifish) (2.19)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install sentifish\n",
    "from sentifish import Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Sentiment` package will be used in the following way. Sentiment( ) is a class. By using this class we can find the sentiment of a texual data(it may be a word, sentence or a paragraph). This class has a constructor init(self,text) which takes the text data at the time of instantiation of Sentiment( ). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Sentiment( ) has a method analyze( ) it returns a float number in between -1 to +1. +1 for strongly positive sentiment, 0 for neutral and -1 for strongly negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_text = \"I hate you\"\n",
    "positive_text = \"I love you\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Negative Comment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity = -0.800\n"
     ]
    }
   ],
   "source": [
    "obj=Sentiment(negative_text)\n",
    "print(\"Sentiment Polarity = {:.3f}\".format(obj.analyze( )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Positive Comment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity = 0.500\n"
     ]
    }
   ],
   "source": [
    "obj=Sentiment(positive_text)\n",
    "print(\"Sentiment Polarity = {:.3f}\".format(obj.analyze( )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using it with text data from our reddit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TLDR; **HOLD GME, leave feedback to the developers of Robinhood to show how much of a disagreement there is in our representation on the app.**\\n\\n&#x200B;\\n\\nIt is shocking to see how much the community can impact the lives around us in such a positive way, but it is hard to see that Robinhood has fucked us with the current gamma squeeze this friday. However, it is optimal for us to remember that next week is the week for this squeeze as mentions by u/wildthangy.\\n\\n&#x200B;\\n\\nSo what is the plan? By no means is this financial advice or market manipulation, as said in the r/WALLSTREETBETS **RULES,** but to allow robinhood to take away our tendies and gains is absurd. REVIEW THEIR APP AND LET THEM KNOW IMMEDIATE FEEDBACK.\\n\\n&#x200B;\\n\\n🚀HOLD GME, AMC, AND BB 🚀'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = reddit_data['body'][98]\n",
    "post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity = 0.077\n"
     ]
    }
   ],
   "source": [
    "obj=Sentiment(post)\n",
    "print(\"Sentiment Polarity = {:.3f}\".format(obj.analyze( )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment of the post above is slightly positive almost neutral according to to the sentiment analyzer method. This makes sense. The poster uses sharp language to describe their distaste of Robinhood. However, this appears to be balanced out by the poster's positive praise of the WSB subreddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point of possible contention arises with posts that feature no post body. Reddit allows users to post topics without writing a post body by design. Below is an example of a post with no body, which is indicated as `NaN` and body length of `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  comms_num body  \\\n",
       "0  Math Professor Scott Steiner says the numbers ...    110         23  NaN   \n",
       "\n",
       "            timestamp  body_len  \n",
       "0 2021-01-28 21:32:10       0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts without body is 4491!\n",
      "Percentage of posts without body is 0.51%!\n"
     ]
    }
   ],
   "source": [
    "count = reddit_data[reddit_data.body_len == 0].shape[0]\n",
    "print(\"Number of posts without body is {}!\".format(count))\n",
    "print(\"Percentage of posts without body is {:.2f}%!\".format(count/reddit_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As illustrated above, a little over half of the posts in the dataset have no post body at all. To control for this, **we will only be considering the post title**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GME Premarket 🍁 Musk approved 🎮🛑💎✋</td>\n",
       "      <td>562</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:17:28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  comms_num body  \\\n",
       "0  Math Professor Scott Steiner says the numbers ...    110         23  NaN   \n",
       "1  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "2  Not to distract from GME, just thought our AMC...     71        156  NaN   \n",
       "3  Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "4                 GME Premarket 🍁 Musk approved 🎮🛑💎✋    562         97  NaN   \n",
       "\n",
       "            timestamp  body_len  \n",
       "0 2021-01-28 21:32:10       0.0  \n",
       "1 2021-01-28 21:28:57       0.0  \n",
       "2 2021-01-28 21:26:56       0.0  \n",
       "3 2021-01-28 21:19:16       0.0  \n",
       "4 2021-01-28 21:17:28       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another consideration is **prevalence of emojis**. Emojis might skew the sentiment polarity score given that we don't know how `sentifish` calculates it. Therefore the function below was written to address this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    return text.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a function to characterize the `sentiment_score` for each post based on its body text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_sentiment(row):\n",
    "    \n",
    "    try: \n",
    "        title_text = deEmojify(row['title'])\n",
    "        obj=Sentiment(title_text)\n",
    "        polarity = obj.analyze( )\n",
    "\n",
    "        return (polarity)\n",
    "    \n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now apply this function on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data['sentiment_score'] = reddit_data.apply(post_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GME Premarket 🍁 Musk approved 🎮🛑💎✋</td>\n",
       "      <td>562</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:17:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  comms_num body  \\\n",
       "0  Math Professor Scott Steiner says the numbers ...    110         23  NaN   \n",
       "1  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "2  Not to distract from GME, just thought our AMC...     71        156  NaN   \n",
       "3  Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "4                 GME Premarket 🍁 Musk approved 🎮🛑💎✋    562         97  NaN   \n",
       "\n",
       "            timestamp  body_len  sentiment_score  \n",
       "0 2021-01-28 21:32:10       0.0            0.000  \n",
       "1 2021-01-28 21:28:57       0.0           -0.277  \n",
       "2 2021-01-28 21:26:56       0.0            0.000  \n",
       "3 2021-01-28 21:19:16       0.0           -0.800  \n",
       "4 2021-01-28 21:17:28       0.0            0.000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can characterize each posted based on its sentiment polarity (positive, neutral, negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_polarity(row):\n",
    "    if row['sentiment_score'] > 0:\n",
    "        return 'Positive'\n",
    "    elif row['sentiment_score'] < 0:\n",
    "        return 'Negative'\n",
    "    else: \n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the function to the entire dataset we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data['sentiment_polarity'] = reddit_data.apply(sentiment_polarity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GME Premarket 🍁 Musk approved 🎮🛑💎✋</td>\n",
       "      <td>562</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:17:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  comms_num body  \\\n",
       "0  Math Professor Scott Steiner says the numbers ...    110         23  NaN   \n",
       "1  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "2  Not to distract from GME, just thought our AMC...     71        156  NaN   \n",
       "3  Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "4                 GME Premarket 🍁 Musk approved 🎮🛑💎✋    562         97  NaN   \n",
       "\n",
       "            timestamp  body_len  sentiment_score sentiment_polarity  \n",
       "0 2021-01-28 21:32:10       0.0            0.000            Neutral  \n",
       "1 2021-01-28 21:28:57       0.0           -0.277           Negative  \n",
       "2 2021-01-28 21:26:56       0.0            0.000            Neutral  \n",
       "3 2021-01-28 21:19:16       0.0           -0.800           Negative  \n",
       "4 2021-01-28 21:17:28       0.0            0.000            Neutral  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the the distribution of postive, neutral, and negative posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     5021\n",
       "Positive    2492\n",
       "Negative    1296\n",
       "Name: sentiment_polarity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['sentiment_polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue by only focusing on positive and negative posts as they should provide us with the most insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = reddit_data[reddit_data.sentiment_polarity != 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    2492\n",
       "Negative    1296\n",
       "Name: sentiment_polarity, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['sentiment_polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_pos = reddit_data.loc[reddit_data['sentiment_score'].idxmax()]['title']\n",
    "most_neg = reddit_data.loc[reddit_data['sentiment_score'].idxmin()]['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the most positive post according to our sentiment methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I got in on GME 74 @ $290. Best of luck bois and gurls'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly here is the most negative post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GME, my worst-case scenario nonsense'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have a baseline for each post polarity, lets train a multivariate linear model to predict sentiment polarity using the features of our dataset: post upvote score, number of comments, post body length, and time of day published (morning, afternoon, evening, night)** Let's see how accurate our model can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, if we wish to utilize the `timestamp` of each post in our proposed model, we must translate the data into something that can be easily parsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new column called `day_period` that will classify each timestamp as either occurring during the morning, afternoon, evening or night. The following division of the day will be used as defined [here](https://learnersdictionary.com/qa/parts-of-the-day-early-morning-late-morning-etc):\n",
    "\n",
    "- Morning : 5 am to 12 pm (noon)                 \n",
    "- Afternoon : 12 pm to 5 pm      (5:00 to 17:00) \n",
    "- Evening : 5 pm to 9 pm         (17:00 to 21:00)\n",
    "- Night : 9 pm to 4 am           (21:00 to 4:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to determine the period of the day using the `datetime hour attribute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_period(row):\n",
    "    hr = row['timestamp'].hour\n",
    "    if hr >= 5 and hr < 12: \n",
    "        return \"morning\"\n",
    "    if hr >= 12 and hr < 17: \n",
    "        return \"afternoon\"\n",
    "    if hr >= 17 and hr < 21: \n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>day_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Really? I can’t even buy GME or AMC for now? 😤</td>\n",
       "      <td>606</td>\n",
       "      <td>376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:47:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I don’t have as much as the rest of you guys b...</td>\n",
       "      <td>365</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:30:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GME Gang - 34 Consecutive Days on NYSE Thresho...</td>\n",
       "      <td>207</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:02:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  score  comms_num body  \\\n",
       "1   NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "3   Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "10     Really? I can’t even buy GME or AMC for now? 😤    606        376  NaN   \n",
       "14  I don’t have as much as the rest of you guys b...    365         60  NaN   \n",
       "16  GME Gang - 34 Consecutive Days on NYSE Thresho...    207         51  NaN   \n",
       "\n",
       "             timestamp  body_len  sentiment_score sentiment_polarity  \\\n",
       "1  2021-01-28 21:28:57       0.0        -0.277000           Negative   \n",
       "3  2021-01-28 21:19:16       0.0        -0.800000           Negative   \n",
       "10 2021-01-28 20:47:20       0.0         0.375000           Positive   \n",
       "14 2021-01-28 20:30:20       0.0         0.033333           Positive   \n",
       "16 2021-01-28 20:02:44       0.0        -0.375000           Negative   \n",
       "\n",
       "   day_period  \n",
       "1       night  \n",
       "3       night  \n",
       "10    evening  \n",
       "14    evening  \n",
       "16    evening  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['day_period'] = reddit_data.apply(get_day_period, axis=1)\n",
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "night        2266\n",
       "morning       831\n",
       "afternoon     468\n",
       "evening       223\n",
       "Name: day_period, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['day_period'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts at night 2266!\n",
      "Percentage of posts at night 0.60%!\n"
     ]
    }
   ],
   "source": [
    "count = reddit_data[reddit_data.day_period == 'night'].shape[0]\n",
    "print(\"Number of posts at night {}!\".format(count))\n",
    "print(\"Percentage of posts at night {:.2f}%!\".format(count/reddit_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like a lot of the posts were posted during the night! This makes sense since not a lot of people are allowed to post, let alone browse reddit, during the day due to school or work obligations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>day_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Really? I can’t even buy GME or AMC for now? 😤</td>\n",
       "      <td>606</td>\n",
       "      <td>376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:47:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I don’t have as much as the rest of you guys b...</td>\n",
       "      <td>365</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:30:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GME Gang - 34 Consecutive Days on NYSE Thresho...</td>\n",
       "      <td>207</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:02:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  score  comms_num body  \\\n",
       "1   NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "3   Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "10     Really? I can’t even buy GME or AMC for now? 😤    606        376  NaN   \n",
       "14  I don’t have as much as the rest of you guys b...    365         60  NaN   \n",
       "16  GME Gang - 34 Consecutive Days on NYSE Thresho...    207         51  NaN   \n",
       "\n",
       "             timestamp  body_len  sentiment_score sentiment_polarity  \\\n",
       "1  2021-01-28 21:28:57       0.0        -0.277000           Negative   \n",
       "3  2021-01-28 21:19:16       0.0        -0.800000           Negative   \n",
       "10 2021-01-28 20:47:20       0.0         0.375000           Positive   \n",
       "14 2021-01-28 20:30:20       0.0         0.033333           Positive   \n",
       "16 2021-01-28 20:02:44       0.0        -0.375000           Negative   \n",
       "\n",
       "   day_period  \n",
       "1       night  \n",
       "3       night  \n",
       "10    evening  \n",
       "14    evening  \n",
       "16    evening  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features of the reddit dataset are ready to be used in a multivariate model to predict the `sentiment_polarity` of a reddit post: `score` (the number of upvotes that the post received), `comms_num` (the number of comments that the post received), `body length` (the character count of the post's body text) and `day_period` (the period during the day the post was authored - morning/afternoon/evening/night)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can begin we must address the presence of categorical data in the day_period column in our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can resolve this issue by creating an `indicator variable`. An indicator variable simply indicates whether or not an observation is in a category of `night`, `evening`, `afternoon`, or `morning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "afternoon  evening  morning  night\n",
       "0          0        0        1        2266\n",
       "                    1        0         831\n",
       "1          0        0        0         468\n",
       "0          1        0        0         223\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = pd.get_dummies(reddit_data['day_period'])\n",
    "dummy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = pd.concat([reddit_data, dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>body_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>day_period</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>morning</th>\n",
       "      <th>night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Currently Holding AMC and NOK - Is it retarded...</td>\n",
       "      <td>200</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:19:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Really? I can’t even buy GME or AMC for now? 😤</td>\n",
       "      <td>606</td>\n",
       "      <td>376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:47:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I don’t have as much as the rest of you guys b...</td>\n",
       "      <td>365</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:30:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GME Gang - 34 Consecutive Days on NYSE Thresho...</td>\n",
       "      <td>207</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 20:02:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  score  comms_num body  \\\n",
       "1   NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29         74  NaN   \n",
       "3   Currently Holding AMC and NOK - Is it retarded...    200        161  NaN   \n",
       "10     Really? I can’t even buy GME or AMC for now? 😤    606        376  NaN   \n",
       "14  I don’t have as much as the rest of you guys b...    365         60  NaN   \n",
       "16  GME Gang - 34 Consecutive Days on NYSE Thresho...    207         51  NaN   \n",
       "\n",
       "             timestamp  body_len  sentiment_score sentiment_polarity  \\\n",
       "1  2021-01-28 21:28:57       0.0        -0.277000           Negative   \n",
       "3  2021-01-28 21:19:16       0.0        -0.800000           Negative   \n",
       "10 2021-01-28 20:47:20       0.0         0.375000           Positive   \n",
       "14 2021-01-28 20:30:20       0.0         0.033333           Positive   \n",
       "16 2021-01-28 20:02:44       0.0        -0.375000           Negative   \n",
       "\n",
       "   day_period  afternoon  evening  morning  night  \n",
       "1       night          0        0        0      1  \n",
       "3       night          0        0        0      1  \n",
       "10    evening          0        1        0      0  \n",
       "14    evening          0        1        0      0  \n",
       "16    evening          0        1        0      0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now Split the reddit data into a training and test set using the `train_test_split()` function. A `random_state` value of 10 will be used to ensure uniformity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reddit Training Set\n",
      "\n",
      "      score  comms_num  body_len  afternoon  evening  morning  night  \\\n",
      "4577    296         14       0.0          0        0        1      0   \n",
      "6596     81         13       0.0          0        0        1      0   \n",
      "8784    175         46    2371.0          1        0        0      0   \n",
      "3129    373         35       0.0          0        0        1      0   \n",
      "3339      1          1       0.0          0        0        0      1   \n",
      "\n",
      "      sentiment_score sentiment_polarity  \n",
      "4577         0.433000           Positive  \n",
      "6596         0.416500           Positive  \n",
      "8784         0.800000           Positive  \n",
      "3129        -0.290333           Negative  \n",
      "3339         0.156250           Positive  \n",
      "Training set has 3030 observations\n",
      "\n",
      "Reddit Test Set\n",
      "\n",
      "      score  comms_num  body_len  afternoon  evening  morning  night  \\\n",
      "502       1          1       0.0          0        0        0      1   \n",
      "8445      7          8       0.0          0        0        1      0   \n",
      "321       4          2      30.0          0        0        0      1   \n",
      "6902     12          9       0.0          0        0        1      0   \n",
      "8528    177         21       0.0          0        0        1      0   \n",
      "\n",
      "      sentiment_score sentiment_polarity  \n",
      "502          0.578667           Positive  \n",
      "8445         0.433000           Positive  \n",
      "321          0.375000           Positive  \n",
      "6902        -0.125000           Negative  \n",
      "8528        -0.400000           Negative  \n",
      "Test set has 758 observations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train-test split (80%/20%)\n",
    "reddit_data_train, reddit_data_test = train_test_split(reddit_data[['score', 'comms_num', 'body_len', 'afternoon', 'evening', 'morning', 'night', 'sentiment_score', 'sentiment_polarity']], test_size= 0.2, random_state = 10)\n",
    "\n",
    "print(\" Reddit Training Set\\n\")\n",
    "print(reddit_data_train.head())\n",
    "print(\"Training set has {} observations\\n\".format(len(reddit_data_train)))\n",
    "\n",
    "print(\"Reddit Test Set\\n\")\n",
    "print(reddit_data_test.head())\n",
    "print(\"Test set has {} observations\\n\".format(len(reddit_data_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create a linear regression object\n",
    "linear_model = LinearRegression() \n",
    "multi_features = ['score', 'comms_num', 'body_len', 'afternoon', 'evening', 'morning', 'night']\n",
    "X = reddit_data_train[ multi_features ]\n",
    "linear_model.fit(X, reddit_data_train['sentiment_score']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model to predict the `sentiment_score` in the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_model.predict(reddit_data_test[multi_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_polarity = []\n",
    "for i in range (0, len(y_pred)):\n",
    "    if y_pred[i] > 0:\n",
    "        y_pred_polarity.append('Positive')\n",
    "    else:\n",
    "        y_pred_polarity.append('Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the accuracy of the linear model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 16.3%\n"
     ]
    }
   ],
   "source": [
    "y_true = reddit_data_test['sentiment_polarity']\n",
    "y_true = y_true.reset_index(drop=True)\n",
    "\n",
    "correct = 0\n",
    "for i in range(0, len(y_true)):\n",
    "    if y_pred_polarity[i] == y_true[i]:\n",
    "        correct += 1\n",
    "    \n",
    "accuracy = correct/len(reddit_data_train)\n",
    "\n",
    "print(\"Prediction Accuracy: {:.1f}%\".format(accuracy *100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the training set's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 65.9%\n"
     ]
    }
   ],
   "source": [
    "y_true = reddit_data_train['sentiment_polarity']\n",
    "y_true = y_true.reset_index(drop=True)\n",
    "\n",
    "y_pred = linear_model.predict(reddit_data_train[multi_features])\n",
    "\n",
    "y_pred_polarity = []\n",
    "for i in range (0, len(y_pred)):\n",
    "    if y_pred[i] > 0:\n",
    "        y_pred_polarity.append('Positive')\n",
    "    else:\n",
    "        y_pred_polarity.append('Negative')\n",
    "\n",
    "correct = 0\n",
    "for i in range(0, len(y_true)):\n",
    "    if y_pred_polarity[i] == y_true[i]:\n",
    "        correct += 1\n",
    "    \n",
    "accuracy = correct/len(reddit_data_train)\n",
    "\n",
    "print(\"Prediction Accuracy: {:.1f}%\".format(accuracy *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Slope = 5.166337461855809e-07 - R^2 = 0.004114846573968434\n"
     ]
    }
   ],
   "source": [
    "r_2 = linear_model.score(X, reddit_data_train['sentiment_score'])\n",
    "slope = linear_model.coef_[0]\n",
    "print(\"Regression Slope = {} - R^2 = {}\".format(slope, r_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit post sentiment appears to not be correlated at all with the given feature list that we selected: `sentiment_polarity`, `score` , `comms_num`, `body length`, and `day_period`.\n",
    "\n",
    "As you increase by one reddit post, you can expect `sentifish` sentiment polarity to increase by almost a negligible amount. The $r^2$ score is 0.004 and it shows that our model doesn’t fit the data very well because it cannot explain all the variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon closer inspection, our model is predicting that almost every post will be positive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Post index: 1282\n",
      "Number of Positive Posts 3029, Number of Negative Posts 1\n"
     ]
    }
   ],
   "source": [
    "pos_count = 0 \n",
    "neg_count = 0\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    if y_pred[i] > 0:\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        neg_count += 1\n",
    "        print(\"Negative Post index: {}\".format(i))\n",
    "\n",
    "print(\"Number of Positive Posts {}, Number of Negative Posts {}\".format(pos_count, neg_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at single negative post that was predicted which was indeed Positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[1282]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Interpretation and Project Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the time period of our analysis, there were some calls for law makers to examine the role of r/wallstreetbets in influencing to stock market. Some people called for the subreddit to be removed on the grounds of it being used for criminal market manipulation. Others called for the subreddit to be removed on the grounds that it was promoting hate speech. The data analysis in our project analyzes the latter concern. We trained a multivariate linear model that predicted the sentiment polarity of a r/wallstreetbets reddit post, either positive or negative, using the following features: the number of upvotes that the post received, the number of comments that the post received, the character count of the post's body text, the period during the day the post was authored - morning/afternoon/evening/night.\n",
    "\n",
    "However, our analysis showed that our model proved to failed in characterizing the sentiment polarity r/wallstreetbets posts based on title. This was our expectation before we conducted our analysis given the reddit dataset. Although unsuccessful and not statistically significant in any way, our model surprisingly predicted all the reddit posts to be of positive sentiment. It seems that r/wallstreetbets functioned more like a 'town square' where users shared their sentiment about stocks, which is no different than Twitter, Facebook, or simple word of mouth. We do not recommend our model to regulators or moderators looking to take sweeping action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Project Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reddit Dataset** - r/wallstreetbets post dataset is primarily limited by the time span in which the data was captured. The posts were recorded starting from Jan 28, 2021. This is one day after the peak stock price of GME on Jan. 27, 2021. It would have been nice to have data capturing posts before Jan 28, 2021 as we could better document user sentiment before GME's rise and its peak. The posts contain information not related to GameStop. This means we would have to find a way to filter relevant posts. We also converted the 'body' column to only record numerical character length instead of the actual body message. \n",
    "\n",
    "**Sentifish** - We opted to use an outside resource in order to conduct the the sentiment analysis for each reddit post. We also do not know how precisely the sentiment was calculated according to the library. The method of sentiment analysis chosen is bounded to produce different results in our project. In the future, we hope to learn to implement such analysis ourselves. Moreover, since not every post had body text, we instead opted to consider only the post's title. We sacrificed potentially more detail in exchange for uniformity.\n",
    "\n",
    "**r/wallstreetbets Moderation** - [the subreddit](https://www.reddit.com/r/wallstreetbets/) appears to have very strict moderation and this is reflected in the limited amount of posts in the 'new' section. Many posts appear to be deleted by moderator if they do not meet a certain standard of quality.\n",
    "\n",
    "**GameStop/GME Reddit Post Search** - the boolean search method used to subset the reddit post data set (see Data Cleaning Appendix) would be prone to filter posts out that are indeed relevant to GameStop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "GitHub: https://github.com/DavidFleurantin/INFO-2950-Final-Project\n",
    "</br>\n",
    "Google Drive Link: https://drive.google.com/drive/folders/1iBHVGOBGvDMe7iT7gU4-bCawfUNaYZwe?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Acknowledgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special thanks is given to the following resources:\n",
    "\n",
    "1. [Kaggle](https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts) - For providing an excellent resource for finding a dataset that formed a basis of our project\n",
    "2. [Sentifish](https://pypi.org/project/sentifish/) - For making sentiment analysis easier\n",
    "3. Stack Overflow\n",
    "    * [Dataframe Boolean Search](https://stackoverflow.com/questions/22909082/pandas-converting-string-object-to-lower-case-and-checking-for-string)\n",
    "    * [Embed Images](https://stackoverflow.com/questions/32370281/how-to-embed-image-or-picture-in-jupyter-notebook-either-from-a-local-machine-o)\n",
    "    * [Combine Dataframes](https://stackoverflow.com/questions/12850345/how-do-i-combine-two-dataframes)\n",
    "    * [Regression with NaN values](https://stackoverflow.com/questions/13643363/linear-regression-of-arrays-containing-nans-in-python-numpy)\n",
    "    * [Lambda Expressions](https://stackoverflow.com/questions/51787247/pandas-update-column-values-from-another-column-if-criteria)\n",
    "    * [Apply Function](https://stackoverflow.com/questions/19914937/applying-function-with-multiple-arguments-to-create-a-new-pandas-column)\n",
    "    * [Datetime Object Floor Function](https://stackoverflow.com/questions/32723150/rounding-up-to-nearest-30-minutes-in-python)\n",
    "    * [Convert Series to Dict](https://stackoverflow.com/questions/29403192/convert-series-returned-by-pandas-series-value-counts-to-a-dictionary)\n",
    "    * [Datetime Hour Attribute](https://stackoverflow.com/questions/21674782/how-to-check-if-a-date-time-is-before-midday)\n",
    "    * [Dummy Variables](https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40)\n",
    "\n",
    "4. TAs/Office Hours - Our **TA Elena** for helping us troubleshoot our problems along the way"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
